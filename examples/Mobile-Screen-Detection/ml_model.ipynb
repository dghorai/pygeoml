{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 17 2022\n",
    "\n",
    "@author: Debabrata Ghorai, Ph.D.\n",
    "\n",
    "Mobile phone screen on/off detection.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(x_train, y_train, h=150, w=150):\n",
    "  \"\"\"Read and resize the image\"\"\"\n",
    "  x_lists = []\n",
    "  y_lists = []\n",
    "  # loop over image and label list\n",
    "  for i, j in zip(x_train, y_train):\n",
    "    try:\n",
    "      # read image\n",
    "      img = cv2.imread(i)\n",
    "      # resize image\n",
    "      img_resize = cv2.resize(img, (w, h))\n",
    "      # reshape numpy array\n",
    "      img_tf = img_resize.reshape((1,)+img_resize.shape)\n",
    "      # append final array and corresponding label to the list\n",
    "      x_lists.append(img_tf)\n",
    "      y_lists.append(int(j))\n",
    "    except Exception as e:\n",
    "      print('Cannot read the image: {}'.format(e))\n",
    "  # return both the list\n",
    "  return x_lists, y_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(height, width, channel, outnode):\n",
    "  \"\"\"CNN for image classification\"\"\"\n",
    "  # build model\n",
    "  model = keras.Sequential()\n",
    "  # learn a total of 32 filters, kernel size 3x3\n",
    "  model.add(layers.Conv2D(32, (3, 3), input_shape=(height, width, channel), padding=\"Same\", activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  #  learn a total of 64 filters, kernel size 3x3\n",
    "  model.add(layers.Conv2D(64, (3, 3), padding=\"Same\", activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  #  learn a total of 100 filters, kernel size 3x3\n",
    "  model.add(layers.Conv2D(64, (3, 3), padding=\"Same\", activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  # flatten the 3D output to 1D\n",
    "  model.add(layers.Flatten())\n",
    "  # add dense layer with relu activation function\n",
    "  model.add(layers.Dense(256, activation='relu'))\n",
    "  model.add(layers.Dense(32, activation='relu'))\n",
    "  # add output layer with softmx activation function \n",
    "  model.add(layers.Dense(outnode, activation='softmax'))\n",
    "  # return model\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(path):\n",
    "    \"\"\"Get all the files with full path\"\"\"\n",
    "    filelist = []\n",
    "    # loop over dirs, sub-dirs, and files\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for fname in files:\n",
    "            if fname.endswith(\".jpg\"):\n",
    "                fpath = os.path.join(root, fname)\n",
    "                # append full path of the file in a list\n",
    "                filelist.append(fpath)\n",
    "    # return final data list\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(filelist, print_stats=False):\n",
    "    \"\"\"Create model training data\"\"\"\n",
    "    try:\n",
    "        # build a dataframe with image full-path and category\n",
    "        df = pd.DataFrame(filelist, columns=[\"data_path\"])\n",
    "\n",
    "        # append class type into dataframe\n",
    "        for ix, row in df.iterrows():\n",
    "            df.loc[ix, 'class_type'] = row['data_path'].split(\"\\\\\")[-2]\n",
    "\n",
    "        # get unique class and their counts\n",
    "        tot_sample = df.shape[0]\n",
    "        class_type_counts = df['class_type'].value_counts()\n",
    "        class_type = class_type_counts.keys().tolist()\n",
    "\n",
    "        # get dataset's basic stats\n",
    "        if print_stats == True:\n",
    "            print(\"Total image count in dataset: \", tot_sample)\n",
    "            print(\"class type: \", class_type)\n",
    "            for view in class_type:\n",
    "                print(view+' total count: '+str(class_type_counts[view]))\n",
    "\n",
    "        # create label of the images\n",
    "        labels = {}\n",
    "        for i, view in enumerate(class_type):\n",
    "            print(view, i)\n",
    "            labels[view] = i\n",
    "\n",
    "        # add label column to df\n",
    "        for ix, row in df.iterrows():\n",
    "            df.loc[ix, 'label'] = labels[row['class_type']]\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error: {}'.format(e))\n",
    "    \n",
    "    # return final dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(filelist, n=12):\n",
    "    \"\"\"Plot figures\"\"\"\n",
    "    # plot some sample images\n",
    "    sample_files = random.sample(filelist, n)\n",
    "    f, ax = plt.subplots(4, 3, figsize=(10, 10))\n",
    "    # loop over sample images and plot them\n",
    "    for i, f in enumerate(sample_files):\n",
    "        image = plt.imread(f)\n",
    "        ax[i//3, i%3].imshow(image)\n",
    "        ax[i//3, i%3].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main directory of the mobile phone dataset\n",
    "path = \"/dataset\"\n",
    "\n",
    "# reading the mobile phone dataset\n",
    "# mobile phone screen on/off image kept in seperate sub-folders\n",
    "# get list of all data paths from all the sub-directory\n",
    "filelist = get_data_list(path)\n",
    "df = create_training_data(filelist, print_stats=True)\n",
    "\n",
    "# plot some sample images/pic\n",
    "plot_images(filelist, n=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # train-test split\n",
    "    x_train_t, x_test_t, y_train_t, y_test_t = train_test_split(df['data_path'], df['label'], test_size=0.2, random_state=0)\n",
    "\n",
    "    # prepare model train/validation datasets\n",
    "    x_lists, y_lists = prepare_data(x_train_t, y_train_t)\n",
    "    X_train_arr = np.concatenate(x_lists)/255.0\n",
    "    y_train_arr = tensorflow.keras.utils.to_categorical(y_lists)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_arr, y_train_arr, test_size=0.2, random_state=0)\n",
    "\n",
    "    # sequential model inputs\n",
    "    _, height, width, channel = X_train.shape\n",
    "    outnode = len(df['label'].unique().tolist())\n",
    "    print(height, width, channel, outnode)\n",
    "except Exception as e:\n",
    "    print('Error: {}'.format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(0)\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "# compile model and check model summary\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model = build_model(height, width, channel, outnode)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callback parameters\n",
    "mcp = ModelCheckpoint(filepath='model_1.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "es = EarlyStopping(monitor='val_loss', patience=10)\n",
    "callbacks = [es, mcp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate the best model version\n",
    "try:\n",
    "    # pepare test data for model prediction\n",
    "    x_test_lists, y_true = prepare_data(x_test_t, y_test_t)\n",
    "    X_test = np.concatenate(x_test_lists)/255.0\n",
    "\n",
    "    # load best model\n",
    "    model = keras.models.load_model('model_1.h5')\n",
    "\n",
    "    # predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # print accuracy score\n",
    "    print(classification_report(y_true, y_pred))\n",
    "except Exception as e:\n",
    "    print('Error: {}'.format(e))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "557697dcf17df3b982ad4e8ce1db7b810c68e6dfeb7f83e882097c9005ae8d89"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
