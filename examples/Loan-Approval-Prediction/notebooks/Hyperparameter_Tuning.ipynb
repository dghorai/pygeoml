{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\work\\\\loan-approval-prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../.')\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hyperparameter_LogisticRegression(X_train, y_train):\n",
    "    \"\"\"logistic regression - hyperparameter tuning\"\"\"\n",
    "    # Creating the hyperparameter grid\n",
    "    c_space = np.logspace(-5, 8, 15)\n",
    "    param_grid = {'C': c_space}\n",
    "    # Instantiating logistic regression classifier\n",
    "    logreg = LogisticRegression()\n",
    "    # Instantiating the GridSearchCV object\n",
    "    logreg_cv = GridSearchCV(logreg, param_grid, cv = 5)\n",
    "    logreg_cv.fit(X_train, y_train)\n",
    "    # Print the tuned parameters and score\n",
    "    print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "    print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hyperparameter_SVC(X_train, y_train):\n",
    "    \"\"\"support vector machine classifier - hyperparameter tuning\"\"\"\n",
    "    # defining parameter range\n",
    "    param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                  'kernel': ['rbf']}\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "    # fitting the model for grid search\n",
    "    grid.fit(X_train, y_train)\n",
    "    # print best parameter after tuning\n",
    "    print(grid.best_params_)\n",
    "    # print how our model looks after hyper-parameter tuning\n",
    "    print(grid.best_estimator_)\n",
    "    print(grid.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hyperparameter_KNN(X_train, y_train):\n",
    "    \"\"\"k-nn - hyperparameter tuning\"\"\"\n",
    "    grid_params = { 'n_neighbors' : [3,5,7,9,11,13,15],\n",
    "                   'weights' : ['uniform','distance'],\n",
    "                   'metric' : ['minkowski','euclidean','manhattan'],\n",
    "                   'p' : [1,2,3,4,5]}\n",
    "    gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=7, n_jobs = -1)\n",
    "    # fit the model on our train set\n",
    "    g_res = gs.fit(X_train, y_train)\n",
    "    # find the best score\n",
    "    print(g_res.best_score_)\n",
    "    # get the hyperparameters with the best score\n",
    "    print(g_res.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hyperparameter_RF(X_train, y_train):\n",
    "    \"\"\"random forest - hyperparameter tuning\"\"\"\n",
    "    # search RF best parameters\n",
    "    forest = RandomForestClassifier(random_state = 0)\n",
    "    n_estimators = [50, 80, 100, 300, 500, 800, 1200]\n",
    "    max_depth = [5, 8, 15, 25, 30]\n",
    "    min_samples_split = [2, 5, 10, 15, 100]\n",
    "    min_samples_leaf = [1, 2, 5, 10] \n",
    "    hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "                  min_samples_split = min_samples_split, \n",
    "                 min_samples_leaf = min_samples_leaf)\n",
    "    # grid-search\n",
    "    gridF = GridSearchCV(forest, hyperF, cv = 3, verbose = 1, n_jobs = -1)\n",
    "    bestF = gridF.fit(X_train, y_train)\n",
    "    print(bestF.best_params_)\n",
    "    print(bestF.best_score_)\n",
    "    # # random-search\n",
    "    # randomF = RandomizedSearchCV(forest, hyperF, random_state=0)\n",
    "    # bestRandomF = randomF.fit(X_train, y_train)\n",
    "    # print(bestRandomF.best_params_)\n",
    "    # print(bestRandomF.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hyperparameter_RF2(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"random forest - best accuracy finding with random_state changing after hyperparameter tuning\"\"\"\n",
    "    for i in range(1, 500):\n",
    "        rfc = RandomForestClassifier(random_state = i, max_depth = 8, n_estimators = 10, min_samples_split = 2, min_samples_leaf = 6)       \n",
    "        rfc.fit(X_train, y_train)\n",
    "        y_pred_rfc = rfc.predict(X_test)\n",
    "        confusion_matrix(y_test, y_pred_rfc)\n",
    "        acc = round(accuracy_score(y_pred_rfc, y_test), 2)\n",
    "        if acc > 0.75:\n",
    "            print(i, acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
