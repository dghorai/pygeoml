{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\work\\\\cifar100classifier-deep-learning'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\work\\\\cifar100classifier-deep-learning'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('src')\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_url: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n",
    "    trainset_file: Path\n",
    "    meta_file: Path\n",
    "    metadata: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNNClassifier.constants import *\n",
    "from CNNClassifier.utils.utilities import read_yaml, create_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directory([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self):\n",
    "        config = self.config.data_ingestion\n",
    "        create_directory([config.root_dir])\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_url=config.source_url,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir,\n",
    "            trainset_file=config.trainset_file,\n",
    "            meta_file=config.meta_file,\n",
    "            metadata=config.metadata\n",
    "        )\n",
    "        return data_ingestion_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import wget\n",
    "import tarfile\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from CNNClassifier import logger\n",
    "from CNNClassifier.entity import DataIngestionConfig\n",
    "from CNNClassifier.utils.utilities import *\n",
    "\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            logger.info(\"trying to download file\")\n",
    "            download_url = self.config.source_url\n",
    "            outfile_path = self.config.local_data_file\n",
    "            try:\n",
    "                response = requests.get(download_url, stream=True)\n",
    "                if response.status_code == 200:\n",
    "                    with open(outfile_path, 'wb') as f:\n",
    "                        f.write(response.raw.read())\n",
    "            except:\n",
    "                wget.download(download_url, out=outfile_path)\n",
    "            logger.info(f\"Downloaded {outfile_path} file successfully!\")\n",
    "        else:\n",
    "            # logger.info(\"file already exists\")\n",
    "            logger.info(f\"File already exists of the size: {get_size(Path(self.config.local_data_file))}\")\n",
    "            return\n",
    "\n",
    "    def unzip_targzfile(self):\n",
    "        targzfile = self.config.local_data_file\n",
    "        outfolder = self.config.unzip_dir\n",
    "        # open file\n",
    "        with tarfile.open(targzfile) as f:\n",
    "            logger.info(f.getnames())\n",
    "            # extract files\n",
    "            f.extractall(outfolder)\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='latin1')\n",
    "        return dict\n",
    "\n",
    "    def get_metadata(self):\n",
    "        train_set = self.unpickle(os.path.join(self.config.unzip_dir, self.config.trainset_file))\n",
    "        meta_data = self.unpickle(os.path.join(self.config.unzip_dir, self.config.meta_file))\n",
    "        # create a data records\n",
    "        file_names = train_set['filenames']\n",
    "        fine_labels = train_set['fine_labels']\n",
    "        coarse_labels = train_set['coarse_labels']\n",
    "        coarse_names = meta_data['coarse_label_names']\n",
    "        fine_names = meta_data['fine_label_names']\n",
    "        images = train_set['data']\n",
    "        n_images = len(images)\n",
    "        images = images.reshape(n_images, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "        # create a dictionary\n",
    "        image_dict = defaultdict(list)\n",
    "        for i in range(n_images):\n",
    "            img = images[i]\n",
    "            image_dict['file_name'].append(file_names[i])\n",
    "            image_dict['fine_labels'].append(fine_labels[i])\n",
    "            image_dict['coarse_labels'].append(coarse_labels[i])\n",
    "            image_dict['fine_label_names'].append(fine_names[fine_labels[i]])\n",
    "            image_dict['coarse_label_names'].append(coarse_names[coarse_labels[i]])\n",
    "            image_dict['image_height'].append(img.shape[0])\n",
    "            image_dict['image_width'].append(img.shape[1])\n",
    "            image_dict['image_channel'].append(img.shape[2])\n",
    "            image_dict['min_pixel'].append(img.min())\n",
    "            image_dict['max_pixel'].append(img.max())\n",
    "        # dict to dataframe\n",
    "        df = pd.DataFrame.from_dict(image_dict)\n",
    "        # save the result for EDA analysis\n",
    "        df.to_csv(os.path.join(self.config.root_dir, self.config.metadata), index=False)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-20 14:18:45,209: INFO: utilities]: yaml file: configs\\config.yaml loaded successfully\n",
      "[2023-10-20 14:18:45,217: INFO: utilities]: yaml file: params.yaml loaded successfully\n",
      "[2023-10-20 14:18:45,220: INFO: utilities]: create directory at: artifacts\n",
      "[2023-10-20 14:18:45,222: INFO: utilities]: create directory at: artifacts/data_ingestion\n",
      "[2023-10-20 14:18:45,224: INFO: 1076953943]: trying to download file\n",
      "[2023-10-20 14:19:47,224: INFO: 1076953943]: Downloaded artifacts/data_ingestion/cifar-100-python.tar.gz file successfully!\n",
      "[2023-10-20 14:19:48,899: INFO: 1076953943]: ['cifar-100-python', 'cifar-100-python/file.txt~', 'cifar-100-python/train', 'cifar-100-python/test', 'cifar-100-python/meta']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.unzip_targzfile()\n",
    "    data_ingestion.get_metadata()\n",
    "except Exception as e:\n",
    "    raise e\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
