{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\work\\\\loan-approval-prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../.')\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# ML MODELS\n",
    "def dt_model(X_train, y_train, X_test, y_test, outdir=None):\n",
    "    dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 123)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred_dt = dt.predict(X_test)\n",
    "    confusion_matrix(y_test, y_pred_dt)\n",
    "    print('accuracy: {}'.format(round(accuracy_score(y_pred_dt, y_test), 2)))\n",
    "    print(classification_report(y_test, y_pred_dt))\n",
    "    filename = os.path.join(outdir, 'dt_model.sav')\n",
    "    pickle.dump(dt, open(filename, 'wb'))\n",
    "    return\n",
    "\n",
    "\n",
    "def rf_model(X_train, y_train, X_test, y_test, outdir=None):\n",
    "    rfc = RandomForestClassifier(random_state = 445, max_depth = 8, n_estimators = 10, min_samples_split = 2, min_samples_leaf = 6)          \n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred_rfc = rfc.predict(X_test)\n",
    "    confusion_matrix(y_test, y_pred_rfc)\n",
    "    print('accuracy: {}'.format(round(accuracy_score(y_pred_rfc, y_test), 2)))\n",
    "    print(classification_report(y_test, y_pred_rfc))\n",
    "    filename = os.path.join(outdir, 'rf_model.sav')\n",
    "    pickle.dump(rfc, open(filename, 'wb'))\n",
    "    return\n",
    "\n",
    "\n",
    "def logistic_model(X_train, y_train, X_test, y_test, outdir=None):\n",
    "    lr = LogisticRegression(C = 4.49)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    confusion_matrix(y_test, y_pred)\n",
    "    print('accuracy: {}'.format(round(accuracy_score(y_pred, y_test), 2)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    filename = os.path.join(outdir, 'lr_model.sav')\n",
    "    pickle.dump(lr, open(filename, 'wb'))\n",
    "    return\n",
    "\n",
    "\n",
    "def svm_model(X_train, y_train, X_test, y_test, outdir=None):\n",
    "    svm = SVC(C=1, gamma=0.1, kernel='rbf')\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred_svm = svm.predict(X_test)\n",
    "    confusion_matrix(y_test, y_pred_svm)\n",
    "    print('accuracy: {}'.format(round(accuracy_score(y_pred_svm, y_test), 2)))\n",
    "    print(classification_report(y_test, y_pred_svm))\n",
    "    filename = os.path.join(outdir, 'svm_model.sav')\n",
    "    pickle.dump(svm, open(filename, 'wb'))\n",
    "    return\n",
    "\n",
    "\n",
    "def knn_model(X_train, y_train, X_test, y_test, outdir=None):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    confusion_matrix(y_test, y_pred_knn)\n",
    "    print('accuracy: {}'.format(round(accuracy_score(y_pred_knn, y_test), 2)))\n",
    "    print(classification_report(y_test, y_pred_knn))\n",
    "    filename = os.path.join(outdir, 'knn_model.sav')\n",
    "    pickle.dump(knn, open(filename, 'wb'))\n",
    "    return\n",
    "\n",
    "\n",
    "def gnb_model(X_train, y_train, X_test, y_test, outdir=None):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    y_pred_gnb = gnb.predict(X_test)\n",
    "    confusion_matrix(y_test, y_pred_gnb)\n",
    "    print('accuracy: {}'.format(round(accuracy_score(y_pred_gnb, y_test), 2)))\n",
    "    print(classification_report(y_test, y_pred_gnb))\n",
    "    filename = os.path.join(outdir, 'gnb_model.sav')\n",
    "    pickle.dump(gnb, open(filename, 'wb'))\n",
    "    return\n",
    "\n",
    "\n",
    "def ann_model(X_train, y_train, X_valid, y_valid, X_test, y_test, outdir=None):\n",
    "    \"\"\"binary classification with ANN model\"\"\"\n",
    "    # ann model\n",
    "    classifier = Sequential()\n",
    "    # Add the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units=7, activation = 'relu'))\n",
    "    classifier.add(Dense(units=7, activation = 'relu'))\n",
    "    classifier.add(Dense(units=1, activation = 'sigmoid'))\n",
    "    # optimizer set\n",
    "    opt = Adam(learning_rate=0.0001)\n",
    "    classifier.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    classifier.build(X_train.shape)\n",
    "    classifier.summary()\n",
    "    # set callback parameters\n",
    "    mcp = ModelCheckpoint(filepath=os.path.join(outdir, 'ann_model.h5'), monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    callbacks = [es, mcp]\n",
    "    \n",
    "    classifier.fit(X_train, y_train, batch_size = 10, validation_data=(X_valid, y_valid), epochs = 500, verbose=1, callbacks=callbacks)\n",
    "    \n",
    "    # predict\n",
    "    y_pred_ann = classifier.predict(X_test)\n",
    "    y_pred_ann = (y_pred_ann > 0.5)\n",
    "    confusion_matrix(y_test, y_pred_ann)\n",
    "    print('accuracy: {}'.format(round(accuracy_score(y_pred_ann, y_test), 2)))\n",
    "    print(classification_report(y_test, y_pred_ann))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import input_dataframe\n",
    "\n",
    "# read data\n",
    "in_file = \"notebooks/data/input_training_data.csv\"\n",
    "\n",
    "df = input_dataframe(in_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 0.0\n",
      "2 0\n",
      "3 2500\n",
      "4 0.0\n",
      "5 120.0\n",
      "6 360.0\n",
      "7 1.0\n",
      "8 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work\\loan-approval-prediction\\src\\utils.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.interpolate(method='linear', limit_direction='backward', inplace=True)\n",
      "d:\\work\\loan-approval-prediction\\src\\utils.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.interpolate(method='linear', limit_direction='forward', inplace=True)\n",
      "d:\\work\\loan-approval-prediction\\src\\utils.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[cols] = X[cols]/div1\n"
     ]
    }
   ],
   "source": [
    "from src.utils import feature_engineering\n",
    "\n",
    "# MODEL BUILDING - 1\n",
    "#=========================\n",
    "# TRAIN-TEST SPLIT: CUSTOM-SCALE\n",
    "#================================\n",
    "out_model_dir = 'artifacts'\n",
    "final_columns = ['Married', 'Dependents', 'Education', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status']\n",
    "\n",
    "df_final = df[final_columns]\n",
    "\n",
    "xysplit = feature_engineering(df_final, colslist=final_columns, return_type='CustomScaler')\n",
    "\n",
    "X_train = xysplit['X_train']\n",
    "X_test = xysplit['X_test']\n",
    "y_train = xysplit['y_train']\n",
    "y_test = xysplit['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.73        46\n",
      "           1       0.68      0.69      0.68        39\n",
      "\n",
      "    accuracy                           0.71        85\n",
      "   macro avg       0.70      0.70      0.70        85\n",
      "weighted avg       0.71      0.71      0.71        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run model\n",
    "dt_model(X_train, y_train, X_test, y_test, outdir=out_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.43      0.57        46\n",
      "           1       0.57      0.90      0.70        39\n",
      "\n",
      "    accuracy                           0.65        85\n",
      "   macro avg       0.70      0.67      0.64        85\n",
      "weighted avg       0.71      0.65      0.63        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model(X_train, y_train, X_test, y_test, outdir=out_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work\\loan-approval-prediction\\src\\utils.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.interpolate(method='linear', limit_direction='backward', inplace=True)\n",
      "d:\\work\\loan-approval-prediction\\src\\utils.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.interpolate(method='linear', limit_direction='forward', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# MODEL BUILDING - 2\n",
    "#=========================\n",
    "# TRAIN-TEST SPLIT: STANDARD-SCALE\n",
    "#==========================================\n",
    "\n",
    "xysplit2 = feature_engineering(df_final, colslist=final_columns, return_type='StandardScaler')\n",
    "\n",
    "X_train2 = xysplit2['X_train']\n",
    "X_test2 = xysplit2['X_test']\n",
    "y_train2 = xysplit2['y_train']\n",
    "y_test2 = xysplit2['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.46      0.62        46\n",
      "           1       0.60      0.97      0.75        39\n",
      "\n",
      "    accuracy                           0.69        85\n",
      "   macro avg       0.78      0.72      0.68        85\n",
      "weighted avg       0.79      0.69      0.68        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run model\n",
    "logistic_model(X_train2, y_train2, X_test2, y_test2, outdir=out_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.48      0.63        46\n",
      "           1       0.61      0.95      0.74        39\n",
      "\n",
      "    accuracy                           0.69        85\n",
      "   macro avg       0.76      0.71      0.68        85\n",
      "weighted avg       0.77      0.69      0.68        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model(X_train2, y_train2, X_test2, y_test2, outdir=out_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.50      0.61        46\n",
      "           1       0.58      0.82      0.68        39\n",
      "\n",
      "    accuracy                           0.65        85\n",
      "   macro avg       0.67      0.66      0.64        85\n",
      "weighted avg       0.68      0.65      0.64        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_model(X_train2, y_train2, X_test2, y_test2, outdir=out_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.52      0.66        46\n",
      "           1       0.62      0.92      0.74        39\n",
      "\n",
      "    accuracy                           0.71        85\n",
      "   macro avg       0.75      0.72      0.70        85\n",
      "weighted avg       0.77      0.71      0.70        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb_model(X_train2, y_train2, X_test2, y_test2, outdir=out_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ANN Model Training\n",
    "X_train1, X_valid, y_train1, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (235, 7)                  70        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (235, 7)                  56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (235, 1)                  8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134\n",
      "Trainable params: 134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "15/24 [=================>............] - ETA: 0s - loss: 207.7948 - accuracy: 0.4333 \n",
      "Epoch 1: val_loss improved from inf to 235.81593, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 3s 22ms/step - loss: 203.8613 - accuracy: 0.4340 - val_loss: 235.8159 - val_accuracy: 0.4412\n",
      "Epoch 2/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 7.1029 - accuracy: 0.4000\n",
      "Epoch 2: val_loss improved from 235.81593 to 226.09846, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 195.3527 - accuracy: 0.4340 - val_loss: 226.0985 - val_accuracy: 0.4412\n",
      "Epoch 3/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.5595 - accuracy: 0.7000\n",
      "Epoch 3: val_loss improved from 226.09846 to 215.91179, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 187.1501 - accuracy: 0.4383 - val_loss: 215.9118 - val_accuracy: 0.4412\n",
      "Epoch 4/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 154.1400 - accuracy: 0.4000\n",
      "Epoch 4: val_loss improved from 215.91179 to 206.20372, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 178.4809 - accuracy: 0.4426 - val_loss: 206.2037 - val_accuracy: 0.4412\n",
      "Epoch 5/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 199.9941 - accuracy: 0.3000\n",
      "Epoch 5: val_loss improved from 206.20372 to 195.88794, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 170.4987 - accuracy: 0.4468 - val_loss: 195.8879 - val_accuracy: 0.4412\n",
      "Epoch 6/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 35.1992 - accuracy: 0.8000\n",
      "Epoch 6: val_loss improved from 195.88794 to 185.59520, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.0634 - accuracy: 0.4511 - val_loss: 185.5952 - val_accuracy: 0.4510\n",
      "Epoch 7/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 272.5147 - accuracy: 0.6000\n",
      "Epoch 7: val_loss improved from 185.59520 to 176.33505, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 153.3607 - accuracy: 0.4511 - val_loss: 176.3351 - val_accuracy: 0.4412\n",
      "Epoch 8/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 198.2298 - accuracy: 0.3000\n",
      "Epoch 8: val_loss improved from 176.33505 to 166.93480, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 145.1122 - accuracy: 0.4511 - val_loss: 166.9348 - val_accuracy: 0.4412\n",
      "Epoch 9/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 64.8441 - accuracy: 0.7000\n",
      "Epoch 9: val_loss improved from 166.93480 to 156.37054, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 136.7948 - accuracy: 0.4511 - val_loss: 156.3705 - val_accuracy: 0.4412\n",
      "Epoch 10/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 167.8004 - accuracy: 0.4000\n",
      "Epoch 10: val_loss improved from 156.37054 to 139.16783, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 125.1652 - accuracy: 0.4511 - val_loss: 139.1678 - val_accuracy: 0.4412\n",
      "Epoch 11/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 125.1290 - accuracy: 0.6000\n",
      "Epoch 11: val_loss improved from 139.16783 to 123.17239, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 111.0556 - accuracy: 0.4511 - val_loss: 123.1724 - val_accuracy: 0.4412\n",
      "Epoch 12/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 96.1185 - accuracy: 0.5000\n",
      "Epoch 12: val_loss improved from 123.17239 to 107.12009, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 98.2409 - accuracy: 0.4511 - val_loss: 107.1201 - val_accuracy: 0.4412\n",
      "Epoch 13/500\n",
      " 9/24 [==========>...................] - ETA: 0s - loss: 74.8156 - accuracy: 0.4667\n",
      "Epoch 13: val_loss improved from 107.12009 to 93.15273, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 84.8702 - accuracy: 0.4468 - val_loss: 93.1527 - val_accuracy: 0.4314\n",
      "Epoch 14/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 113.4828 - accuracy: 0.5000\n",
      "Epoch 14: val_loss improved from 93.15273 to 78.37380, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 72.6636 - accuracy: 0.4468 - val_loss: 78.3738 - val_accuracy: 0.4314\n",
      "Epoch 15/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 76.8330 - accuracy: 0.5000\n",
      "Epoch 15: val_loss improved from 78.37380 to 64.29404, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 60.2189 - accuracy: 0.4383 - val_loss: 64.2940 - val_accuracy: 0.4314\n",
      "Epoch 16/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 62.5994 - accuracy: 0.3000\n",
      "Epoch 16: val_loss improved from 64.29404 to 49.27381, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 48.2961 - accuracy: 0.4383 - val_loss: 49.2738 - val_accuracy: 0.4314\n",
      "Epoch 17/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 35.6289 - accuracy: 0.4000\n",
      "Epoch 17: val_loss improved from 49.27381 to 34.71040, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 35.7335 - accuracy: 0.4383 - val_loss: 34.7104 - val_accuracy: 0.4314\n",
      "Epoch 18/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 31.2734 - accuracy: 0.2000\n",
      "Epoch 18: val_loss improved from 34.71040 to 19.95640, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.6970 - accuracy: 0.4426 - val_loss: 19.9564 - val_accuracy: 0.4314\n",
      "Epoch 19/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 16.7598 - accuracy: 0.4000\n",
      "Epoch 19: val_loss improved from 19.95640 to 5.69878, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 11.7424 - accuracy: 0.4426 - val_loss: 5.6988 - val_accuracy: 0.4314\n",
      "Epoch 20/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 5.5880 - accuracy: 0.6000\n",
      "Epoch 20: val_loss improved from 5.69878 to 1.57647, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8382 - accuracy: 0.4936 - val_loss: 1.5765 - val_accuracy: 0.5588\n",
      "Epoch 21/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.7647 - accuracy: 0.5000\n",
      "Epoch 21: val_loss improved from 1.57647 to 0.84379, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.3247 - accuracy: 0.4809 - val_loss: 0.8438 - val_accuracy: 0.5392\n",
      "Epoch 22/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.9139 - accuracy: 0.5000\n",
      "Epoch 22: val_loss did not improve from 0.84379\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.8069 - accuracy: 0.4681 - val_loss: 1.3001 - val_accuracy: 0.4118\n",
      "Epoch 23/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6888 - accuracy: 0.3000\n",
      "Epoch 23: val_loss improved from 0.84379 to 0.79837, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.0205 - accuracy: 0.4511 - val_loss: 0.7984 - val_accuracy: 0.4706\n",
      "Epoch 24/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.7984 - accuracy: 0.5000\n",
      "Epoch 24: val_loss did not improve from 0.79837\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.7744 - accuracy: 0.5064 - val_loss: 1.0719 - val_accuracy: 0.4314\n",
      "Epoch 25/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.0405 - accuracy: 0.2000\n",
      "Epoch 25: val_loss did not improve from 0.79837\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9964 - accuracy: 0.4979 - val_loss: 0.8095 - val_accuracy: 0.4510\n",
      "Epoch 26/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.6933 - accuracy: 0.5000\n",
      "Epoch 26: val_loss improved from 0.79837 to 0.79579, saving model to artifacts\\ann_model.h5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.9364 - accuracy: 0.4511 - val_loss: 0.7958 - val_accuracy: 0.4510\n",
      "Epoch 27/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.7729 - accuracy: 0.3000\n",
      "Epoch 27: val_loss did not improve from 0.79579\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.8553 - accuracy: 0.4894 - val_loss: 0.8204 - val_accuracy: 0.4216\n",
      "Epoch 28/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.6857 - accuracy: 0.3000\n",
      "Epoch 28: val_loss did not improve from 0.79579\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.8968 - accuracy: 0.4681 - val_loss: 1.0254 - val_accuracy: 0.4314\n",
      "Epoch 29/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.8084 - accuracy: 0.5000\n",
      "Epoch 29: val_loss did not improve from 0.79579\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9061 - accuracy: 0.4723 - val_loss: 0.9186 - val_accuracy: 0.4118\n",
      "Epoch 30/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.6962 - accuracy: 0.4000\n",
      "Epoch 30: val_loss did not improve from 0.79579\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.8550 - accuracy: 0.5021 - val_loss: 0.9764 - val_accuracy: 0.4216\n",
      "Epoch 31/500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.7660 - accuracy: 0.7000\n",
      "Epoch 31: val_loss did not improve from 0.79579\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7926 - accuracy: 0.5064 - val_loss: 1.0998 - val_accuracy: 0.4314\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "accuracy: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.50      0.49        46\n",
      "           1       0.39      0.38      0.39        39\n",
      "\n",
      "    accuracy                           0.45        85\n",
      "   macro avg       0.44      0.44      0.44        85\n",
      "weighted avg       0.45      0.45      0.45        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run ann model\n",
    "ann_model(X_train1, y_train1, X_valid, y_valid, X_test, y_test, outdir=out_model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
